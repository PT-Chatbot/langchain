{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memoria\n",
    "La memoria ayuda a que los LLMs tengan la capacidad de recordas información a largo plazo. De manera muy general, la memoria es un historico de todas las interacciones que se han tenido con el modelo y se integra en el prompt que se le envia, de manera que el modelo pueda recordar lo que se le ha enviado previamente.\n",
    "\n",
    "Dado que los LLMs tienen una ventana de contexto finita, hay distintas maneras de implementar la memoria. En este cuaderno veremos:\n",
    "* Conversation buffer\n",
    "* Conversation buffer window\n",
    "* Conversation summary\n",
    "* Knowledge graph memory\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation buffer\n",
    "Esta es una de las memorias más básicas, cada prompt y respuesta del modelos se almacenara en la memoria. Cada vez que se le envia un nuevo prompt al modelo se envia todo el historico de las interacciones. \n",
    "\n",
    "La conversación se salva como pares de mensajes entre \"Human\" y \"AI\", por lo cual tambien lo podemos integrar con modelos como GPT3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp, OpenAI\n",
    "import config\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = config.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI()\n",
    "memoria = ConversationBufferMemory()\n",
    "chatbot = ConversationChain(llm=llm, memory=memoria, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hola como estas?, Me llamo Marcos y soy un programador\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola Marcos! ¡Qué alegría conocerte! Soy un programa de inteligencia artificial diseñado para ayudar en diversas tareas. ¿En qué puedo asistirte hoy?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.predict(input=\"Hola como estas?, Me llamo Marcos y soy un programador\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hola como estas?, Me llamo Marcos y soy un programador\n",
      "AI: ¡Hola Marcos! ¡Qué alegría conocerte! Soy un programa de inteligencia artificial diseñado para ayudar en diversas tareas. ¿En qué puedo asistirte hoy?\n",
      "Human: Como me llamo?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tu nombre es Marcos.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.predict(input=\"Como me llamo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hola como estas?, Me llamo Marcos y soy un programador'),\n",
       " AIMessage(content='¡Hola Marcos! ¡Qué alegría conocerte! Soy un programa de inteligencia artificial diseñado para ayudar en diversas tareas. ¿En qué puedo asistirte hoy?'),\n",
       " HumanMessage(content='Como me llamo?'),\n",
       " AIMessage(content='Tu nombre es Marcos.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memoria.chat_memory.messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation buffer window memory\n",
    "Esta memoria es igual a la anterior, con la diferencia que se puede definir una ventana de mensajes a recordar en vez de recordar todo el historico de interacciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "memoria = ConversationBufferWindowMemory(k=2)\n",
    "chatbot = ConversationChain(llm=llm, memory=memoria, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hola como estas?, Me llamo Marcos y soy un programador\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola Marcos! ¡Encantado de conocerte! Estoy muy bien, gracias por preguntar. Como programador, supongo que te gusta trabajar con códigos y algoritmos, ¿verdad?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.predict(input=\"Hola como estas?, Me llamo Marcos y soy un programador\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hola como estas?, Me llamo Marcos y soy un programador\n",
      "AI: ¡Hola Marcos! ¡Encantado de conocerte! Estoy muy bien, gracias por preguntar. Como programador, supongo que te gusta trabajar con códigos y algoritmos, ¿verdad?\n",
      "Human: como me llamo?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tu nombre es Marcos.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.predict(input = \"como me llamo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hola como estas?, Me llamo Marcos y soy un programador\n",
      "AI: ¡Hola Marcos! ¡Encantado de conocerte! Estoy muy bien, gracias por preguntar. Como programador, supongo que te gusta trabajar con códigos y algoritmos, ¿verdad?\n",
      "Human: como me llamo?\n",
      "AI: Tu nombre es Marcos.\n",
      "Human: Cuanto mide el sol?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'El sol tiene un diámetro de aproximadamente 1.4 millones de kilómetros. ¡Es una estrella realmente impresionante!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.predict(input=\"Cuanto mide el sol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: como me llamo?\n",
      "AI: Tu nombre es Marcos.\n",
      "Human: Cuanto mide el sol?\n",
      "AI: El sol tiene un diámetro de aproximadamente 1.4 millones de kilómetros. ¡Es una estrella realmente impresionante!\n",
      "Human: Cuanto mide la luna?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La Luna tiene un diámetro de aproximadamente 3,474.8 kilómetros. ¡Es mucho más pequeña que el Sol, pero igual de fascinante!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.predict(input=\"Cuanto mide la luna?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Cuanto mide el sol?\n",
      "AI: El sol tiene un diámetro de aproximadamente 1.4 millones de kilómetros. ¡Es una estrella realmente impresionante!\n",
      "Human: Cuanto mide la luna?\n",
      "AI: La Luna tiene un diámetro de aproximadamente 3,474.8 kilómetros. ¡Es mucho más pequeña que el Sol, pero igual de fascinante!\n",
      "Human: Cuanto mide mercurio?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mercurio tiene un diámetro de aproximadamente 4,880 kilómetros. Es el planeta más pequeño de nuestro sistema solar, pero tiene características interesantes como su superficie llena de cráteres.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.predict(input=\"Cuanto mide mercurio?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Cuanto mide la luna?\n",
      "AI: La Luna tiene un diámetro de aproximadamente 3,474.8 kilómetros. ¡Es mucho más pequeña que el Sol, pero igual de fascinante!\n",
      "Human: Cuanto mide mercurio?\n",
      "AI: Mercurio tiene un diámetro de aproximadamente 4,880 kilómetros. Es el planeta más pequeño de nuestro sistema solar, pero tiene características interesantes como su superficie llena de cráteres.\n",
      "Human: Como me llamo?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lo siento, no tengo esa información. ¿Podrías decirme tu nombre?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.predict(input=\"Como me llamo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hola como estas?, Me llamo Marcos y soy un programador'),\n",
       " AIMessage(content='¡Hola Marcos! ¡Encantado de conocerte! Estoy muy bien, gracias por preguntar. Como programador, supongo que te gusta trabajar con códigos y algoritmos, ¿verdad?'),\n",
       " HumanMessage(content='como me llamo?'),\n",
       " AIMessage(content='Tu nombre es Marcos.'),\n",
       " HumanMessage(content='Cuanto mide el sol?'),\n",
       " AIMessage(content='El sol tiene un diámetro de aproximadamente 1.4 millones de kilómetros. ¡Es una estrella realmente impresionante!'),\n",
       " HumanMessage(content='Cuanto mide la luna?'),\n",
       " AIMessage(content='La Luna tiene un diámetro de aproximadamente 3,474.8 kilómetros. ¡Es mucho más pequeña que el Sol, pero igual de fascinante!'),\n",
       " HumanMessage(content='Cuanto mide mercurio?'),\n",
       " AIMessage(content='Mercurio tiene un diámetro de aproximadamente 4,880 kilómetros. Es el planeta más pequeño de nuestro sistema solar, pero tiene características interesantes como su superficie llena de cráteres.'),\n",
       " HumanMessage(content='Como me llamo?'),\n",
       " AIMessage(content='Lo siento, no tengo esa información. ¿Podrías decirme tu nombre?')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memoria.chat_memory.messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation summary memory\n",
    "Esta memoria en vez de almacenar un registro detallado de las interacciones, almacena un resumen de la conversación. Muy util para evitar prompts muy largos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "llm = ChatOpenAI(stop=[\"\\nHuman\"])\n",
    "#llm_k = OpenAI(stop=[\"\\nHuman\"])\n",
    "memoria = ConversationSummaryMemory(llm=llm)\n",
    "chatbot_resumen = ConversationChain(llm=llm, memory=memoria, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Me gusta mucho la tecnologia y la programacion, en especial python y javascript. Estoy aprendiendo a usar redes neuronales y me gusta mucho la inteligencia artificial\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Qué interesante! La tecnología y la programación son campos fascinantes. Python y JavaScript son lenguajes de programación muy populares y versátiles. Las redes neuronales son un área emocionante de la inteligencia artificial, ¿sabías que se inspiran en el funcionamiento del cerebro humano? Es genial que estés aprendiendo sobre ello. ¿Hay algo en particular que te gustaría saber más sobre la inteligencia artificial?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_resumen.predict(input=\"Me gusta mucho la tecnologia y la programacion, en especial python y javascript. Estoy aprendiendo a usar redes neuronales y me gusta mucho la inteligencia artificial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human expresses their love for technology and programming, especially Python and JavaScript. They mention learning about neural networks and their interest in artificial intelligence. The AI responds enthusiastically, highlighting the popularity and versatility of Python and JavaScript in programming. The AI also shares insights about neural networks being inspired by the human brain's functioning and encourages the human to explore more about artificial intelligence.\n",
      "Human: Que te gusta a ti de la tecnologia?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Me encanta la tecnología por su capacidad para simplificar tareas, aumentar la eficiencia y conectar a las personas de todo el mundo. Además, me fascina la programación, especialmente Python y JavaScript, por su versatilidad y facilidad de uso. También me apasiona aprender sobre redes neuronales y el campo de la inteligencia artificial en general.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_resumen.predict(\n",
    "    input=\"Que te gusta a ti de la tecnologia?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guarda el historico de la conversacion, pero al momento de enviar el promp solo envia un *resumen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Me gusta mucho la tecnologia y la programacion, en especial python y javascript. Estoy aprendiendo a usar redes neuronales y me gusta mucho la inteligencia artificial'),\n",
       " AIMessage(content='¡Qué interesante! La tecnología y la programación son campos fascinantes. Python y JavaScript son lenguajes de programación muy populares y versátiles. Las redes neuronales son un área emocionante de la inteligencia artificial, ¿sabías que se inspiran en el funcionamiento del cerebro humano? Es genial que estés aprendiendo sobre ello. ¿Hay algo en particular que te gustaría saber más sobre la inteligencia artificial?'),\n",
       " HumanMessage(content='Que te gusta a ti de la tecnologia?'),\n",
       " AIMessage(content='Me encanta la tecnología por su capacidad para simplificar tareas, aumentar la eficiencia y conectar a las personas de todo el mundo. Además, me fascina la programación, especialmente Python y JavaScript, por su versatilidad y facilidad de uso. También me apasiona aprender sobre redes neuronales y el campo de la inteligencia artificial en general.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memoria.chat_memory.messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Knowledge Graph Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genera un grafo de conocimiento en donde almacena piezas clave de la conversacion para poder responder con ese contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(stop=[\"\\nHuman\"])\n",
    "memoria = ConversationKGMemory(llm=llm)\n",
    "chatbot_kgm = ConversationChain(llm=llm, memory=memoria, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hola, me llamo Marcos y soy un programador, me gusta la pizza y tengo un gato de mascota, mi color favorito es el azul y me gusta mucho la tecnologia\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola Marcos! ¡Qué gusto conocerte! Soy un programa de inteligencia artificial diseñado para ayudarte en lo que necesites. Me encanta la pizza también, ¿tienes alguna preferencia de toppings? Y tu gato debe ser una compañía maravillosa, ¿cuál es su nombre? El azul es un color muy bonito, ¿sabías que se asocia con la calma y la serenidad? Y como programador, seguro que estás al tanto de las últimas tendencias tecnológicas. ¿Hay algún proyecto en particular en el que estés trabajando actualmente? ¡Cuéntame más sobre ti, estoy aquí para escucharte!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_kgm.predict(input = \"Hola, me llamo Marcos y soy un programador, me gusta la pizza y tengo un gato de mascota, mi color favorito es el azul y me gusta mucho la tecnologia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Marcos', 'Marcos', 'se llama'), ('Marcos', 'programador', 'es'), ('Marcos', 'gato de mascota', 'tiene'), ('Marcos', 'azul', 'color favorito es'), ('Marcos', 'tecnologia', 'le gusta')]\n"
     ]
    }
   ],
   "source": [
    "print(chatbot_kgm.memory.kg.get_triples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hola, me llamo Marcos y soy un programador, me gusta la pizza y tengo un gato de mascota, mi color favorito es el azul y me gusta mucho la tecnologia'),\n",
       " AIMessage(content='¡Hola Marcos! ¡Qué gusto conocerte! Soy un programa de inteligencia artificial diseñado para ayudarte en lo que necesites. Me encanta la pizza también, ¿tienes alguna preferencia de toppings? Y tu gato debe ser una compañía maravillosa, ¿cuál es su nombre? El azul es un color muy bonito, ¿sabías que se asocia con la calma y la serenidad? Y como programador, seguro que estás al tanto de las últimas tendencias tecnológicas. ¿Hay algún proyecto en particular en el que estés trabajando actualmente? ¡Cuéntame más sobre ti, estoy aquí para escucharte!')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memoria.chat_memory.messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando GPT3\n",
    "Las implementaciones que vimos son usando gpt3.5 turbo, pero si quieres hacerlo con gtp instruct como Davinci, Ada Curie o Babbage es muy similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hola, como estas?, me llamo Marcos y soy un programador\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hola Marcos, soy una inteligencia artificial creada por un equipo de programadores. Estoy programada para aprender y comunicarme con humanos como tú. ¿En qué lenguajes de programación estás especializado?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hola, como estas?, me llamo Marcos y soy un programador\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
